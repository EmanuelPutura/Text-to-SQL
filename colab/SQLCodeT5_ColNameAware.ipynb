{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SQLCodeT5-ColNameAware model"
      ],
      "metadata": {
        "id": "dDNsW4Nf483e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Z5LZYC-u-h",
        "outputId": "920dcc6a-a694-470d-c82c-034a719b5e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqDuG9hq8g8d"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets rouge_score transformers==4.28.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFb0uUJv8nx8"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "\n",
        "T5_MODEL = 'Salesforce/codet5-small'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(T5_MODEL)\n",
        "model = T5ForConditionalGeneration.from_pretrained(T5_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL1RA2kU8oaZ",
        "outputId": "bb381af7-db76-47fa-a0ef-00a855867275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset wikisql (/root/.cache/huggingface/datasets/wikisql/default/0.1.0/7037bfe6a42b1ca2b6ac3ccacba5253b1825d31379e9cc626fc79a620977252d)\n",
            "WARNING:datasets.builder:Found cached dataset wikisql (/root/.cache/huggingface/datasets/wikisql/default/0.1.0/7037bfe6a42b1ca2b6ac3ccacba5253b1825d31379e9cc626fc79a620977252d)\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_data = load_dataset('wikisql', split='train+validation')\n",
        "test_data = load_dataset('wikisql', split='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC_EI2fp8sK-"
      },
      "outputs": [],
      "source": [
        "def get_table_from_row(row):\n",
        "  header = row['table']['header']\n",
        "  data_types = row['table']['types']\n",
        "\n",
        "  table_str = \"Table(\" + \", \".join([f\"\\'{h}\\'\" for h in header]) + \")\"\n",
        "  return table_str\n",
        "\n",
        "def format_dataset(example):\n",
        "  return {'input': 'translate to SQL the following natural language query: \\'{}\\', where the table is \\'{}\\''.format(example['question'], get_table_from_row(example)), 'target': example['sql']['human_readable']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tme88G5Z9Ia-",
        "outputId": "c45cc9e4-5aa2-401c-a48b-99489aa7a5eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/wikisql/default/0.1.0/7037bfe6a42b1ca2b6ac3ccacba5253b1825d31379e9cc626fc79a620977252d/cache-b3c350e09d95f6fe.arrow\n"
          ]
        }
      ],
      "source": [
        "train_data = train_data.map(format_dataset, remove_columns=train_data.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5XW4qfT9JB1",
        "outputId": "c569f37a-a225-449b-a445-d7f69ba6bf38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/wikisql/default/0.1.0/7037bfe6a42b1ca2b6ac3ccacba5253b1825d31379e9cc626fc79a620977252d/cache-9f3dc234f3498395.arrow\n"
          ]
        }
      ],
      "source": [
        "test_data = test_data.map(format_dataset, remove_columns=test_data.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnAtvsmL9MUG"
      },
      "outputs": [],
      "source": [
        "# tokenize the examples\n",
        "def convert_to_features(example_batch):\n",
        "    input_encodings = tokenizer.batch_encode_plus(example_batch['input'], pad_to_max_length=True, max_length=64)\n",
        "    target_encodings = tokenizer.batch_encode_plus(example_batch['target'], pad_to_max_length=True, max_length=64)\n",
        "\n",
        "    encodings = {\n",
        "        'input_ids': input_encodings['input_ids'],\n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'labels': target_encodings['input_ids'],\n",
        "        'decoder_attention_mask': target_encodings['attention_mask'],\n",
        "    }\n",
        "\n",
        "    return encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_RW1Nuf9N0L",
        "outputId": "dfa0ebca-3a78-4c9e-aebb-8759164b32f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/wikisql/default/0.1.0/7037bfe6a42b1ca2b6ac3ccacba5253b1825d31379e9cc626fc79a620977252d/cache-07d155eef58e5c4d.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/wikisql/default/0.1.0/7037bfe6a42b1ca2b6ac3ccacba5253b1825d31379e9cc626fc79a620977252d/cache-e0a08b011ca1465d.arrow\n"
          ]
        }
      ],
      "source": [
        "train_data = train_data.map(convert_to_features, batched=True, remove_columns=train_data.column_names)\n",
        "test_data = test_data.map(convert_to_features, batched=True, remove_columns=test_data.column_names)\n",
        "\n",
        "columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
        "\n",
        "train_data.set_format(type='torch', columns=columns)\n",
        "test_data.set_format(type='torch', columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-okVCC19PyP"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import Seq2SeqTrainingArguments\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "PATH_TO_TRAINED_MODEL = '/content/drive/MyDrive/model0306_1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAFvNrWP9XEl",
        "outputId": "0753b447-36ca-4970-cb35-0435af1c1352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_qNL3-R9xj2"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=PATH_TO_TRAINED_MODEL,\n",
        "    per_device_train_batch_size=128,\n",
        "    num_train_epochs=15,\n",
        "    per_device_eval_batch_size=128,\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    logging_steps=500,\n",
        "    save_strategy=\"epoch\",\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hndLSi1c90Ul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbed0e3a-d91e-491a-c652-90a9e1d4e45a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-ff41f60595c8>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  rouge = load_metric(\"rouge\")\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "rouge = load_metric(\"rouge\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels_ids = pred.label_ids\n",
        "  pred_ids = pred.predictions\n",
        "\n",
        "  # all unnecessary tokens are removed\n",
        "  pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "  labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "  label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "  rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
        "\n",
        "  return {\n",
        "      \"rouge2_precision\": round(rouge_output.precision, 4),\n",
        "      \"rouge2_recall\": round(rouge_output.recall, 4),\n",
        "      \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=test_data,\n",
        ")"
      ],
      "metadata": {
        "id": "pSSZBSrr-zO-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "00f05af1-f282-433e-8cf0-f9e49766cbf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-591fcc0e5b3b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# instantiate trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m trainer = Seq2SeqTrainer(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Seq2SeqTrainer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "w3tADhWP-0TV",
        "outputId": "678cb077-6321-4ac7-a4fd-c38a9d878847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 2.5842812061309814,\n",
              " 'eval_rouge2_precision': 0.0068,\n",
              " 'eval_rouge2_recall': 0.0016,\n",
              " 'eval_rouge2_fmeasure': 0.0025,\n",
              " 'eval_runtime': 95.0103,\n",
              " 'eval_samples_per_second': 167.119,\n",
              " 'eval_steps_per_second': 1.316}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "YHJv16-X-0-b",
        "outputId": "988d34fa-e9a5-4629-9103-20d928812bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7605' max='7605' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7605/7605 2:43:05, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge2 Precision</th>\n",
              "      <th>Rouge2 Recall</th>\n",
              "      <th>Rouge2 Fmeasure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.176700</td>\n",
              "      <td>0.086866</td>\n",
              "      <td>0.876500</td>\n",
              "      <td>0.817900</td>\n",
              "      <td>0.841200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.096800</td>\n",
              "      <td>0.071974</td>\n",
              "      <td>0.889600</td>\n",
              "      <td>0.830700</td>\n",
              "      <td>0.854400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.080300</td>\n",
              "      <td>0.065402</td>\n",
              "      <td>0.895600</td>\n",
              "      <td>0.839000</td>\n",
              "      <td>0.861700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.070300</td>\n",
              "      <td>0.061048</td>\n",
              "      <td>0.899800</td>\n",
              "      <td>0.843100</td>\n",
              "      <td>0.865800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.062900</td>\n",
              "      <td>0.058336</td>\n",
              "      <td>0.904200</td>\n",
              "      <td>0.845900</td>\n",
              "      <td>0.869400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>0.056869</td>\n",
              "      <td>0.907500</td>\n",
              "      <td>0.847700</td>\n",
              "      <td>0.871900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.053400</td>\n",
              "      <td>0.054682</td>\n",
              "      <td>0.908200</td>\n",
              "      <td>0.849300</td>\n",
              "      <td>0.873100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.050200</td>\n",
              "      <td>0.054154</td>\n",
              "      <td>0.909200</td>\n",
              "      <td>0.850700</td>\n",
              "      <td>0.874400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.047000</td>\n",
              "      <td>0.053312</td>\n",
              "      <td>0.909700</td>\n",
              "      <td>0.851300</td>\n",
              "      <td>0.874800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.044800</td>\n",
              "      <td>0.052743</td>\n",
              "      <td>0.910800</td>\n",
              "      <td>0.852100</td>\n",
              "      <td>0.875800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.043300</td>\n",
              "      <td>0.052214</td>\n",
              "      <td>0.910700</td>\n",
              "      <td>0.852200</td>\n",
              "      <td>0.875900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.041400</td>\n",
              "      <td>0.052010</td>\n",
              "      <td>0.912000</td>\n",
              "      <td>0.853400</td>\n",
              "      <td>0.877100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.040200</td>\n",
              "      <td>0.051944</td>\n",
              "      <td>0.911900</td>\n",
              "      <td>0.853200</td>\n",
              "      <td>0.876900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.039900</td>\n",
              "      <td>0.051783</td>\n",
              "      <td>0.912400</td>\n",
              "      <td>0.853700</td>\n",
              "      <td>0.877400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.038700</td>\n",
              "      <td>0.051609</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.854100</td>\n",
              "      <td>0.877700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 12:21]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=7605, training_loss=0.06255210240681966, metrics={'train_runtime': 9786.951, 'train_samples_per_second': 99.279, 'train_steps_per_second': 0.777, 'total_flos': 1.643793849778176e+16, 'train_loss': 0.06255210240681966, 'epoch': 15.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(PATH_TO_TRAINED_MODEL)"
      ],
      "metadata": {
        "id": "2_qInQB1-1xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(PATH_TO_TRAINED_MODEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4Hovtop-2XY",
        "outputId": "d6ccf8a1-688f-48b6-b679-0478cc60b3ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/model0306_1/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/model0306_1/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/model0306_1/vocab.json',\n",
              " '/content/drive/MyDrive/model0306_1/merges.txt',\n",
              " '/content/drive/MyDrive/model0306_1/added_tokens.json',\n",
              " '/content/drive/MyDrive/model0306_1/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}